<!doctype html><html lang=en style=font-size:115%><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content><meta name=description content="Dealing with low fps video can make re-identification of individuals between frames more difficult as the potential targets tend to &ldquo;jump&rdquo; between frames in a way that throws off trackers. Here, I show how applying a Gaussian jitter or wiggle to artificially increase the fps of the video can improve tracking."><link rel=apple-touch-icon sizes=180x180 href=https://www.tdj28.org//images/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://www.tdj28.org//images/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://www.tdj28.org//images/favicon-16x16.png><meta name=keywords content='hugo latex theme blog texify texify2 texify3 michael neuper'><link rel=stylesheet href=/katex/katex.min.css><script defer defer src=/katex/katex.min.js></script><script defer src=/katex/contrib/auto-render.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:url" content="https://www.tdj28.org/blog/2024/08/18/wiggle-while-you-work-using-jittering-to-augment-object-tracking-in-low-fps-videos/"><meta property="og:site_name" content="TDJ28"><meta property="og:title" content="Wiggle while you work: using jittering to augment object tracking in low fps videos"><meta property="og:description" content="Dealing with low fps video can make re-identification of individuals between frames more difficult as the potential targets tend to “jump” between frames in a way that throws off trackers. Here, I show how applying a Gaussian jitter or wiggle to artificially increase the fps of the video can improve tracking."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-08-18T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-19T00:55:18-07:00"><meta property="article:tag" content="Computer Vision"><meta property="article:tag" content="Yolo"><meta property="article:tag" content="Bytetrack"><meta property="og:image" content="https://www.tdj28.org/blog/2024/08/18/wiggle-while-you-work-using-jittering-to-augment-object-tracking-in-low-fps-videos/featured_image.png"><link rel=canonical href=https://www.tdj28.org/blog/2024/08/18/wiggle-while-you-work-using-jittering-to-augment-object-tracking-in-low-fps-videos/><meta itemprop=name content="Wiggle while you work: using jittering to augment object tracking in low fps videos"><meta itemprop=description content="Dealing with low fps video can make re-identification of individuals between frames more difficult as the potential targets tend to “jump” between frames in a way that throws off trackers. Here, I show how applying a Gaussian jitter or wiggle to artificially increase the fps of the video can improve tracking."><meta itemprop=datePublished content="2024-08-18T00:00:00+00:00"><meta itemprop=dateModified content="2024-08-19T00:55:18-07:00"><meta itemprop=wordCount content="1427"><meta itemprop=image content="https://www.tdj28.org/blog/2024/08/18/wiggle-while-you-work-using-jittering-to-augment-object-tracking-in-low-fps-videos/featured_image.png"><meta itemprop=keywords content="Computer Vision,Yolo,Bytetrack"><link rel=stylesheet href=/css/common.min.34f60e2333422e738b86e195a0bf4d119a27c761ea0e3f065acc94818eb81b78.css integrity="sha256-NPYOIzNCLnOLhuGVoL9NEZonx2HqDj8GWsyUgY64G3g=" crossorigin=anonymous><link rel=stylesheet href=/css/content.min.abafa49a3586683e185d210e8ce738faf8e41ad0649c62dd0193ad3e113d4f58.css integrity="sha256-q6+kmjWGaD4YXSEOjOc4+vjkGtBknGLdAZOtPhE9T1g=" crossorigin=anonymous><link rel=stylesheet href=/css/alerts.min.352561072eb67d9a0ed2b2302cd947c2a2472565dcec07f7aaaa378f4cb1cd48.css integrity="sha256-NSVhBy62fZoO0rIwLNlHwqJHJWXc7Af3qqo3j0yxzUg=" crossorigin=anonymous><title>Wiggle while you work: using jittering to augment object tracking in low fps videos - TDJ28</title><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.tdj28.org/blog/2024/08/18/wiggle-while-you-work-using-jittering-to-augment-object-tracking-in-low-fps-videos/featured_image.png"><meta name=twitter:title content="Wiggle while you work: using jittering to augment object tracking in low fps videos"><meta name=twitter:description content="Dealing with low fps video can make re-identification of individuals between frames more difficult as the potential targets tend to “jump” between frames in a way that throws off trackers. Here, I show how applying a Gaussian jitter or wiggle to artificially increase the fps of the video can improve tracking."><link rel=stylesheet href=/css/single.min.2c2574d9e8af69a9179e48afd33ba67bcdb66b6b016348527ee45ae452fe03d2.css integrity="sha256-LCV02eivaakXnkiv0zume822a2sBY0hSfuRa5FL+A9I=" crossorigin=anonymous><link rel=stylesheet href=/css/single.min.78a121b7d7a160420f9daab0ea13add66c37b9c44f27bba07b27207e2b0975d2.css integrity="sha256-eKEht9ehYEIPnaqw6hOt1mw3ucRPJ7ugeycgfisJddI=" crossorigin=anonymous><link rel=stylesheet href=/css/alerts.min.352561072eb67d9a0ed2b2302cd947c2a2472565dcec07f7aaaa378f4cb1cd48.css integrity="sha256-NSVhBy62fZoO0rIwLNlHwqJHJWXc7Af3qqo3j0yxzUg=" crossorigin=anonymous><link rel=stylesheet href=/css/blog-images.min.393fdc10547572cb9729b3ee9dbf63390d39cdc54c4594ff0b5655766997f533.css integrity="sha256-OT/cEFR1csuXKbPunb9jOQ05zcVMRZT/C1ZVdmmX9TM=" crossorigin=anonymous></head><body><div id=wrapper><header id=header><h1><a href=https://www.tdj28.org/>TDJ28</a>
<button id=dark-mode-toggle class=dark-mode-toggle aria-label="Toggle theme">
<svg width="2rem" height="2rem" viewBox="0 0 496 496"><path fill="currentColor" d="M8 256C8 393 119 504 256 504S504 393 504 256 393 8 256 8 8 119 8 256zM256 440V72a184 184 0 010 368z" transform="translate(-8 -8)"/></svg></button></h1><nav><span class=nav-bar-item><span class=icon><svg width="1em" height="1em" viewBox="0 0 24 24"><path d="M17 11H16a1 1 0 000 2h1a1 1 0 000-2zm0 4H16a1 1 0 000 2h1a1 1 0 000-2zM11 9h6a1 1 0 000-2H11a1 1 0 000 2zM21 3H7A1 1 0 006 4V7H3A1 1 0 002 8V18a3 3 0 003 3H18a4 4 0 004-4V4A1 1 0 0021 3zM6 18a1 1 0 01-2 0V9H6zm14-1a2 2 0 01-2 2H7.82A3 3 0 008 18V5H20zm-9-4h1a1 1 0 000-2H11a1 1 0 000 2zm0 4h1a1 1 0 000-2H11a1 1 0 000 2z"/></svg>
</span><a class=link href=/blog/>Blog</a>
</span><span class=nav-bar-item><span class=icon><svg width="1em" height="1em" viewBox="0 0 24 24"><path d="M2.88 16.88a3 3 0 000 4.24 3 3 0 004.24.0 3 3 0 00-4.24-4.24zm2.83 2.83a1 1 0 01-1.42-1.42 1 1 0 011.42.0 1 1 0 010 1.42zM5 12a1 1 0 000 2 5 5 0 015 5 1 1 0 002 0 7 7 0 00-7-7zM5 8a1 1 0 000 2 9 9 0 019 9 1 1 0 002 0 11.08 11.08.0 00-3.22-7.78A11.08 11.08.0 005 8zm10.61.39A15.11 15.11.0 005 4 1 1 0 005 6 13 13 0 0118 19a1 1 0 002 0A15.11 15.11.0 0015.61 8.39z"/></svg>
</span><a class=link href=/index.xml>RSS</a>
</span><span class=nav-bar-item><span class=icon><svg width="1em" height="1em" viewBox="0 0 24 24" data-name="Layer 1"><path d="M10.07031 20.50291a1.00008 1.00008.0 00-1.18115-.9834c-1.30908.24024-2.96191.27637-3.40137-.958a5.70754 5.70754.0 00-1.83691-2.415 1.20073 1.20073.0 01-.1665-.10938 1 1 0 00-.93067-.64551H2.54883a.99965.99965.0 00-1 .99512c-.00391.81543.811 1.33789 1.1416 1.51465a4.4408 4.4408.0 01.92383 1.35937c.36426 1.02344 1.42285 2.57617 4.46582 2.376.001.03516.00195.06836.00244.09863l.00439.26758a1 1 0 002 0l-.00488-.31836C10.07715 21.4951 10.07031 21.22068 10.07031 20.50291zm10.667-15.126c.03174-.125.063-.26367.09034-.41992a6.27792 6.27792.0 00-.40821-3.293 1.002 1.002.0 00-.61572-.58007c-.356-.12012-1.67041-.35645-4.18408 1.25a13.86918 13.86918.0 00-6.354.0C6.76221.751 5.45459.9658 5.10205 1.07908a.99744.99744.0 00-.63135.584 6.3003 6.3003.0 00-.40332 3.35644c.02442.12793.05078.2461.07813.35449A6.26928 6.26928.0 002.89014 9.20311a8.42168 8.42168.0 00.04248.92187c.334 4.60254 3.334 5.98438 5.42431 6.459-.04345.125-.083.25878-.11816.40039a1.00023 1.00023.0 001.94238.47851 1.6784 1.6784.0 01.46778-.87793.99947.99947.0 00-.5459-1.74512c-3.4541-.39453-4.95362-1.80175-5.1792-4.89843a6.61076 6.61076.0 01-.03369-.73828 4.25769 4.25769.0 01.91943-2.71289 3.022 3.022.0 01.1958-.23145.99988.99988.0 00.188-1.02441A3.3876 3.3876.0 016.0381 4.6787 4.09356 4.09356.0 016.1167 3.06346a7.54263 7.54263.0 012.415 1.17968 1.00877 1.00877.0 00.82764.13282 11.77716 11.77716.0 016.17285.001 1.00549 1.00549.0 00.83056-.13769 7.572 7.572.0 012.40528-1.19043 4.03977 4.03977.0 01.0874 1.57812 3.205 3.205.0 01-.16895.60743.9999.9999.0 00.188 1.02441c.07715.08691.1543.18066.22363.26855A4.12186 4.12186.0 0120 9.20311a7.03888 7.03888.0 01-.0376.77734c-.22021 3.05566-1.72558 4.46387-5.1958 4.85937a1 1 0 00-.54541 1.7461 1.63079 1.63079.0 01.46631.9082 3.06079 3.06079.0 01.09229.81934v2.334C14.77 21.2949 14.77 21.78025 14.77 22.00291a1 1 0 102 0c0-.2168.0-.69238.00977-1.33984V18.31346a4.8815 4.8815.0 00-.15479-1.31153 4.25638 4.25638.0 00-.11621-.416 6.51258 6.51258.0 005.44531-6.42383A8.69677 8.69677.0 0022 9.20311 6.13062 6.13062.0 0020.7373 5.37693z"/></svg>
</span><a class=link href=https://github.com/tdj28>GitHub</a>
</span><span class=nav-bar-item><span class=icon><svg width="1em" height="1em" viewBox="0 0 24 24"><path d="M22.46 6c-.77.35-1.6.58-2.46.69C20.88 6.16 21.56 5.32 21.88 4.31 21.05 4.81 20.13 5.16 19.16 5.36 18.37 4.5 17.26 4 16 4c-2.35.0-4.27 1.92-4.27 4.29C11.73 8.63 11.77 8.96 11.84 9.27 8.28 9.09 5.11 7.38 3 4.79c-.37.63-.58 1.37-.58 2.15.0 1.49.75 2.81 1.91 3.56C3.62 10.5 2.96 10.3 2.38 10V10.03c0 2.08 1.48 3.82 3.44 4.21C5.46 14.34 5.08 14.39 4.69 14.39 4.42 14.39 4.15 14.36 3.89 14.31c.54 1.69 2.11 2.95 4 2.98-1.46 1.16-3.31 1.84-5.33 1.84C2.22 19.13 1.88 19.11 1.54 19.07 3.44 20.29 5.7 21 8.12 21 16 21 20.33 14.46 20.33 8.79 20.33 8.6 20.33 8.42 20.32 8.23 21.16 7.63 21.88 6.87 22.46 6z"/></svg>
</span><a class=link href=https://x.com/tdj11100>Twitter</a></span></nav></header><hr class=head-rule></hr><main id=main class=post><article class="content numbered-subtitles"><p>In the realm of computer vision, dealing with low FPS (frames per second) video presents unique challenges, especially when attempting to maintain consistent object tracking.</p><p>Here I try an approach that involves cloning multiple copies of each low FPS video&rsquo;s frames and applying small,
random positional shifts to each clone in order to artificially generate higher FPS video. By adding these minor wiggles, the tracker
gains more samples of an identified individual&ndash;each with a slight perturbation in the location of the individual relative to the original source frame. This seems (not verified yet) to provide the lost_track_buffer with more frames allowing the model to build better confidence in its identifications. The precise mechanisms behind why this jitter improves tracking are beyond the scope of this brief demo, but well worth investigating.</p><p>The key variables we control when setting up the ByteTrack instance are:</p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td>track_activation_threshold</td><td>float</td><td>Confidence threshold for track activation. Higher values improve stability but may miss detections.</td><td>0.25</td></tr><tr><td>lost_track_buffer</td><td>int</td><td>Frames to buffer when a track is lost. Higher values reduce the chance of track fragmentation.</td><td>30</td></tr><tr><td>minimum_matching_threshold</td><td>float</td><td>Threshold for matching tracks with detections. Higher values reduce false positives but may cause fragmentation.</td><td>0.8</td></tr><tr><td>frame_rate</td><td>int</td><td>The frame rate of the video.</td><td>30</td></tr><tr><td>minimum_consecutive_frames</td><td>int</td><td>Frames needed to consider a track valid. Higher values prevent false tracks but may miss short tracks.</td><td>1</td></tr></tbody></table><p>These variables can be set with some reasonable guesses, but future work might also run scans across different values of these variables to find the optimal ranges for their use cases. To that end, the reader may find just as much if not more value in fine tuning the variables for ByteTrack than introducing jitter. This demo only shows one example of how jitter improved tracking.</p><ul><li>detections of people are done via YOLO<ul><li>YOLO is a widely used family of models for object detection.</li></ul></li><li>object tracking via the <code>supervision</code> implementation of ByteTrack<ul><li>ByteTrack is an efficient tracking algorithm designed for multi-object tracking (MOT). It builds on top of the popular SORT (Simple Online and Realtime Tracking) and DeepSORT algorithms.</li></ul></li></ul><h3 id=method>Method</h3><h3 id=getting-low-fps-demo-video>Getting low FPS demo video</h3><p>First, generate an image using a GenAI tooling. Here is an example of an image of an apartment courtyard with a few people walking, created using DALLE:</p><p><img src=/blog/2024/08/18/wiggle-while-you-work-using-jittering-to-augment-object-tracking-in-low-fps-videos/image.png alt="GenAI generated image (via DALLE)"></p><p>I next create a synthetic video via RunwayML using this image as the starting frame. As of the writing of this post, Alpha 3 turbo generates ten seconds of video at 24 fps:</p><div class=video-container><iframe width=560 height=315 src=https://www.youtube.com/embed/S5doxU8cw4Y frameborder=0 allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div><br><p>The video isn&rsquo;t perfect, with weird artifacts such as two people forming from one. However, it suffices to demonstrate the power of
jittering.</p><p>We can downscale that to 1fps with this ffmpeg command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ffmpeg -i input_video.mp4 -vf <span class=s2>&#34;fps=1&#34;</span> -c:v libx264 -crf <span class=m>23</span> -preset veryslow -an output_1fps.mp4
</span></span></code></pre></div><p>resulting in this much lower frame rate video:</p><div class=video-container><iframe width=560 height=315 src=https://www.youtube.com/embed/y6ZGks7tYoo frameborder=0 allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div><br><p>When I process this video with YOLOv8/ByteTrack, I get poor tracking. Wherever you see the word YOLO in the bounding box attributes rather than Object ID, that means that while YOLO detected a person, ByteTrack couldn&rsquo;t track it, which happens a lot in the 1fps video:</p><div class=video-container><iframe width=560 height=315 src=https://www.youtube.com/embed/KCcKCdhYz_s frameborder=0 allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div><br><p>We can see the failure of ByteTrack in this graph which shows Yolo detections and ByteTrack ids, where the latter line is consistently lower than the detections:</p><p><img src=/blog/2024/08/18/wiggle-while-you-work-using-jittering-to-augment-object-tracking-in-low-fps-videos/image-1.png alt="graph showing that bytetrack didn’t track most of the yolo detections"></p><h3 id=ex-uno-plures>ex uno plures</h3><p>Is there a CPU/GPU cheap way to artificially increase the framerate? One way is that I could provide a jitter of the image where I shift it slightly up, down, left, or right, using a Gaussian distribution.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>wiggle_frame</span><span class=p>(</span><span class=n>frame</span><span class=p>,</span> <span class=n>shift_std</span><span class=o>=</span><span class=mi>2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Apply a small random shift to the frame.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>rows</span><span class=p>,</span> <span class=n>cols</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>frame</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=n>x_shift</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>shift_std</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>y_shift</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>shift_std</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Translation matrix for the frame</span>
</span></span><span class=line><span class=cl>    <span class=n>M</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>x_shift</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>y_shift</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Apply the translation to the frame</span>
</span></span><span class=line><span class=cl>    <span class=n>wiggled_frame</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>warpAffine</span><span class=p>(</span><span class=n>frame</span><span class=p>,</span> <span class=n>M</span><span class=p>,</span> <span class=p>(</span><span class=n>cols</span><span class=p>,</span> <span class=n>rows</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>wiggled_frame</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>increase_fps</span><span class=p>(</span><span class=n>input_video_filename</span><span class=p>,</span> <span class=n>target_fps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>cap</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoCapture</span><span class=p>(</span><span class=n>input_video_filename</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>original_fps</span> <span class=o>=</span> <span class=n>cap</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>cv2</span><span class=o>.</span><span class=n>CAP_PROP_FPS</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>original_frame_count</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>cap</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>cv2</span><span class=o>.</span><span class=n>CAP_PROP_FRAME_COUNT</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>frame_duration</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>original_fps</span>
</span></span><span class=line><span class=cl>    <span class=n>target_frame_count</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>original_frame_count</span> <span class=o>*</span> <span class=n>target_fps</span> <span class=o>/</span> <span class=n>original_fps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Prepare the output video</span>
</span></span><span class=line><span class=cl>    <span class=n>output_filename</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>splitext</span><span class=p>(</span><span class=n>input_video_filename</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span><span class=si>}</span><span class=s2>_wiggle_</span><span class=si>{</span><span class=n>target_fps</span><span class=si>}</span><span class=s2>fps.mp4&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>fourcc</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoWriter_fourcc</span><span class=p>(</span><span class=o>*</span><span class=s1>&#39;mp4v&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>width</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>cap</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>cv2</span><span class=o>.</span><span class=n>CAP_PROP_FRAME_WIDTH</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>height</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>cap</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>cv2</span><span class=o>.</span><span class=n>CAP_PROP_FRAME_HEIGHT</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>out</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoWriter</span><span class=p>(</span><span class=n>output_filename</span><span class=p>,</span> <span class=n>fourcc</span><span class=p>,</span> <span class=n>target_fps</span><span class=p>,</span> <span class=p>(</span><span class=n>width</span><span class=p>,</span> <span class=n>height</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Process each frame</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>original_frame_count</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=n>ret</span><span class=p>,</span> <span class=n>frame</span> <span class=o>=</span> <span class=n>cap</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=n>ret</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Write the original frame first</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Generate additional frames to meet the target FPS</span>
</span></span><span class=line><span class=cl>        <span class=n>num_wiggles</span> <span class=o>=</span> <span class=n>target_fps</span> <span class=o>-</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_wiggles</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>wiggled_frame</span> <span class=o>=</span> <span class=n>wiggle_frame</span><span class=p>(</span><span class=n>frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>out</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>wiggled_frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cap</span><span class=o>.</span><span class=n>release</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>out</span><span class=o>.</span><span class=n>release</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Processed video saved as </span><span class=si>{</span><span class=n>output_filename</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>This produces the jittered equivalent of the original 1fps video:</p><div class=video-container><iframe width=560 height=315 src=https://www.youtube.com/embed/EE3uRB8FVzA frameborder=0 allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div><br><h3 id=detecting-with-the-jittered-video>Detecting with the jittered video</h3><p>Next we run the same detection against the jittered video, finding substantially better tracking than the original 1fps video:</p><div class=video-container><iframe width=560 height=315 src=https://www.youtube.com/embed/sBnNw92_AOo frameborder=0 allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div><br><p>We can see this graphed here, where the YOLO detections and the ByteTrack detections line up far better, albeit not perfectly. The in/out metrics aren&rsquo;t perfect either, though better than the original 1fps; however, fine tuning these detections was not the focus of the demo.
The false detections for the in/out metric seem to coincide with dropouts in the ByteTrack detections, something that could likely be improved greatly by binning over detections rather than letting every single frame dictate a bump in the in/out metrics.</p><p><img src=/blog/2024/08/18/wiggle-while-you-work-using-jittering-to-augment-object-tracking-in-low-fps-videos/image-2.png alt="jitter results show YOLO detections and the ByteTrack detections line up far better"></p><p>There is an inverse spiky behavior when the ByteTrack detections drop out in a small percentage of the synthetic frames; this could possibly be solved by binning over N frames and taking the majority detection as the bin&rsquo;s detection.</p><h2 id=next-steps>Next steps</h2><p>Even though this method is substantially less intensive to run than any attempts to morph between frames, and it will likely be less accurate than those methods, this trick demonstrates in this example a substantial improvement in tracking over the original low frame-rate video. Ways this could be refined include:</p><ul><li>Could this improve detections in some higher fps video as well?</li><li>Explore how many artificial frames we need to create for this trick to work effectively; the less the better to preserve cpu/gpu cycles</li><li>Trying to find the optimal jitter magnitude and frequency, minimizing the number of artificial frames we need to create</li><li>Reducing the jitter to just regions that cover bounding boxes of detection (saving CPU/GPU cycles)</li><li>Doing an bin-ensemble analysis over the artificial extra frame identification results, instead of letting every single frame&rsquo;s results have a say (which leads to more false positive/negative results)</li><li>Combining ByteTrack with some further augmentations, or making improvements to ByteTrack</li><li>Exploring other models</li><li>More sophisticated solutions such as&mldr;?</li></ul><h2 id=code-samples>Code samples</h2><p>The detection/id function:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>analyze_video</span><span class=p>(</span><span class=n>input_video_filename</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Initialize lists to store data for plotting</span>
</span></span><span class=line><span class=cl>    <span class=n>yolo_detections_per_frame</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>tracked_detections_per_frame</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>in_counts_per_frame</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>out_counts_per_frame</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>frame_numbers</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>output_base</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>splitext</span><span class=p>(</span><span class=n>input_video_filename</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>output_video_filename</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>output_base</span><span class=si>}</span><span class=s2>_processed.mp4&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>output_png_filename</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>output_base</span><span class=si>}</span><span class=s2>.png&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>base_fps</span> <span class=o>=</span> <span class=n>get_video_fps</span><span class=p>(</span><span class=n>input_video_filename</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Reinitialize the tracker for each video</span>
</span></span><span class=line><span class=cl>    <span class=n>tracker</span> <span class=o>=</span> <span class=n>sv</span><span class=o>.</span><span class=n>ByteTrack</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>lost_track_buffer</span><span class=o>=</span><span class=mi>80</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>track_activation_threshold</span><span class=o>=</span><span class=mf>0.02</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>minimum_matching_threshold</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>frame_rate</span><span class=o>=</span><span class=n>base_fps</span>  <span class=c1># Adjust according to the actual frame rate of your video</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>classes</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>names</span><span class=o>.</span><span class=n>values</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>LINE_STARTS</span><span class=p>,</span> <span class=n>LINE_END</span> <span class=o>=</span> <span class=n>sv</span><span class=o>.</span><span class=n>Point</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>400</span><span class=p>),</span> <span class=n>sv</span><span class=o>.</span><span class=n>Point</span><span class=p>(</span><span class=mi>1280</span><span class=p>,</span> <span class=mi>400</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>box_annotator</span> <span class=o>=</span> <span class=n>sv</span><span class=o>.</span><span class=n>BoxAnnotator</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>label_annotator</span> <span class=o>=</span> <span class=n>sv</span><span class=o>.</span><span class=n>LabelAnnotator</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>line_counter</span> <span class=o>=</span> <span class=n>sv</span><span class=o>.</span><span class=n>LineZone</span><span class=p>(</span><span class=n>start</span><span class=o>=</span><span class=n>LINE_STARTS</span><span class=p>,</span> <span class=n>end</span><span class=o>=</span><span class=n>LINE_END</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>line_annotator</span> <span class=o>=</span> <span class=n>sv</span><span class=o>.</span><span class=n>LineZoneAnnotator</span><span class=p>(</span><span class=n>thickness</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>text_thickness</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>text_scale</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>video_info</span> <span class=o>=</span> <span class=n>sv</span><span class=o>.</span><span class=n>VideoInfo</span><span class=o>.</span><span class=n>from_video_path</span><span class=p>(</span><span class=n>video_path</span><span class=o>=</span><span class=n>input_video_filename</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Process the video frames</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>sv</span><span class=o>.</span><span class=n>VideoSink</span><span class=p>(</span><span class=n>target_path</span><span class=o>=</span><span class=n>output_video_filename</span><span class=p>,</span> <span class=n>video_info</span><span class=o>=</span><span class=n>video_info</span><span class=p>)</span> <span class=k>as</span> <span class=n>sink</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>frame_index</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>frame</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=p>(</span><span class=n>sv</span><span class=o>.</span><span class=n>get_video_frames_generator</span><span class=p>(</span><span class=n>source_path</span><span class=o>=</span><span class=n>input_video_filename</span><span class=p>),</span> <span class=n>total</span><span class=o>=</span><span class=n>video_info</span><span class=o>.</span><span class=n>total_frames</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>enhanced_frame</span> <span class=o>=</span> <span class=n>enhance_frame</span><span class=p>(</span><span class=n>frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Run YOLO on the frame</span>
</span></span><span class=line><span class=cl>            <span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>enhanced_frame</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>conf</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>iou</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>detections</span> <span class=o>=</span> <span class=n>sv</span><span class=o>.</span><span class=n>Detections</span><span class=o>.</span><span class=n>from_ultralytics</span><span class=p>(</span><span class=n>results</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>detections</span> <span class=o>=</span> <span class=n>detections</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>((</span><span class=n>detections</span><span class=o>.</span><span class=n>class_id</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span> <span class=o>|</span> <span class=p>(</span><span class=n>detections</span><span class=o>.</span><span class=n>class_id</span> <span class=o>==</span> <span class=mi>2</span><span class=p>)</span> <span class=o>|</span> <span class=p>(</span><span class=n>detections</span><span class=o>.</span><span class=n>class_id</span> <span class=o>==</span> <span class=mi>7</span><span class=p>))]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Collect the number of YOLO detections</span>
</span></span><span class=line><span class=cl>            <span class=n>yolo_detections_per_frame</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>detections</span><span class=o>.</span><span class=n>xyxy</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Apply the narrowing to all detections</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>bbox</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>detections</span><span class=o>.</span><span class=n>xyxy</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>detections</span><span class=o>.</span><span class=n>xyxy</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>narrow_bounding_box</span><span class=p>(</span><span class=n>bbox</span><span class=p>,</span> <span class=n>reduction_ratio</span><span class=o>=</span><span class=mf>0.6</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Track the detections</span>
</span></span><span class=line><span class=cl>            <span class=n>detections_tracked</span> <span class=o>=</span> <span class=n>tracker</span><span class=o>.</span><span class=n>update_with_detections</span><span class=p>(</span><span class=n>detections</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Collect the number of tracked detections</span>
</span></span><span class=line><span class=cl>            <span class=n>tracked_detections_per_frame</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>detections_tracked</span><span class=o>.</span><span class=n>xyxy</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Annotate frame with bounding boxes and labels</span>
</span></span><span class=line><span class=cl>            <span class=n>annotated_frame</span> <span class=o>=</span> <span class=n>enhanced_frame</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Annotate YOLO detections (even if not tracked)</span>
</span></span><span class=line><span class=cl>            <span class=n>annotated_frame</span> <span class=o>=</span> <span class=n>box_annotator</span><span class=o>.</span><span class=n>annotate</span><span class=p>(</span><span class=n>scene</span><span class=o>=</span><span class=n>annotated_frame</span><span class=p>,</span> <span class=n>detections</span><span class=o>=</span><span class=n>detections</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>labels</span> <span class=o>=</span> <span class=p>[</span><span class=sa>f</span><span class=s2>&#34;YOLO: </span><span class=si>{</span><span class=n>classes</span><span class=p>[</span><span class=n>detections</span><span class=o>.</span><span class=n>class_id</span><span class=p>[</span><span class=n>i</span><span class=p>]]</span><span class=si>}</span><span class=s2> </span><span class=si>{</span><span class=n>detections</span><span class=o>.</span><span class=n>confidence</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>                      <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>detections</span><span class=o>.</span><span class=n>class_id</span><span class=p>))]</span>
</span></span><span class=line><span class=cl>            <span class=n>annotated_frame</span> <span class=o>=</span> <span class=n>label_annotator</span><span class=o>.</span><span class=n>annotate</span><span class=p>(</span><span class=n>scene</span><span class=o>=</span><span class=n>annotated_frame</span><span class=p>,</span> <span class=n>detections</span><span class=o>=</span><span class=n>detections</span><span class=p>,</span> <span class=n>labels</span><span class=o>=</span><span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Annotate tracked detections</span>
</span></span><span class=line><span class=cl>            <span class=n>annotated_frame</span> <span class=o>=</span> <span class=n>box_annotator</span><span class=o>.</span><span class=n>annotate</span><span class=p>(</span><span class=n>scene</span><span class=o>=</span><span class=n>annotated_frame</span><span class=p>,</span> <span class=n>detections</span><span class=o>=</span><span class=n>detections_tracked</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>tracked_labels</span> <span class=o>=</span> <span class=p>[</span><span class=sa>f</span><span class=s2>&#34;#</span><span class=si>{</span><span class=n>detections_tracked</span><span class=o>.</span><span class=n>tracker_id</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=si>}</span><span class=s2> </span><span class=si>{</span><span class=n>classes</span><span class=p>[</span><span class=n>detections_tracked</span><span class=o>.</span><span class=n>class_id</span><span class=p>[</span><span class=n>i</span><span class=p>]]</span><span class=si>}</span><span class=s2> </span><span class=si>{</span><span class=n>detections_tracked</span><span class=o>.</span><span class=n>confidence</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>                              <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>detections_tracked</span><span class=o>.</span><span class=n>class_id</span><span class=p>))]</span>
</span></span><span class=line><span class=cl>            <span class=n>annotated_frame</span> <span class=o>=</span> <span class=n>label_annotator</span><span class=o>.</span><span class=n>annotate</span><span class=p>(</span><span class=n>scene</span><span class=o>=</span><span class=n>annotated_frame</span><span class=p>,</span> <span class=n>detections</span><span class=o>=</span><span class=n>detections_tracked</span><span class=p>,</span> <span class=n>labels</span><span class=o>=</span><span class=n>tracked_labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Handle line crossing and collect in/out counts</span>
</span></span><span class=line><span class=cl>            <span class=n>line_counter</span><span class=o>.</span><span class=n>trigger</span><span class=p>(</span><span class=n>detections</span><span class=o>=</span><span class=n>detections_tracked</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>annotated_frame</span> <span class=o>=</span> <span class=n>line_annotator</span><span class=o>.</span><span class=n>annotate</span><span class=p>(</span><span class=n>frame</span><span class=o>=</span><span class=n>annotated_frame</span><span class=p>,</span> <span class=n>line_counter</span><span class=o>=</span><span class=n>line_counter</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Store in/out counts</span>
</span></span><span class=line><span class=cl>            <span class=n>in_counts_per_frame</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>line_counter</span><span class=o>.</span><span class=n>in_count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>out_counts_per_frame</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>line_counter</span><span class=o>.</span><span class=n>out_count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Write the annotated frame to the output video</span>
</span></span><span class=line><span class=cl>            <span class=n>sink</span><span class=o>.</span><span class=n>write_frame</span><span class=p>(</span><span class=n>frame</span><span class=o>=</span><span class=n>annotated_frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Collect frame number for plotting</span>
</span></span><span class=line><span class=cl>            <span class=n>frame_numbers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>frame_index</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>frame_index</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Plotting the results</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Plot YOLO detections with a solid line</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>frame_numbers</span><span class=p>,</span> <span class=n>yolo_detections_per_frame</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;YOLO Detections&#34;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;blue&#34;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Plot ByteTrack detections with a solid line</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>frame_numbers</span><span class=p>,</span> <span class=n>tracked_detections_per_frame</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;ByteTrack Detections&#34;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;green&#34;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Plot in counts with a solid line</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>frame_numbers</span><span class=p>,</span> <span class=n>in_counts_per_frame</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;In Counts&#34;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;red&#34;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Plot out counts with a solid line</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>frame_numbers</span><span class=p>,</span> <span class=n>out_counts_per_frame</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Out Counts&#34;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;purple&#34;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&#34;Frame Number&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&#34;Count&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&#34;YOLO Detections, ByteTrack Detections, and In/Out Counts&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=n>output_png_filename</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><h2 id=references>References</h2><p><a href=https://arxiv.org/abs/2110.06864>https://arxiv.org/abs/2110.06864</a></p><p><a href=https://github.com/ifzhang/ByteTrack>https://github.com/ifzhang/ByteTrack</a></p><p><a href=https://roboflow.com/model/bytetrack>https://roboflow.com/model/bytetrack</a></p><p><a href=https://www.datature.io/blog/introduction-to-bytetrack-multi-object-tracking-by-associating-every-detection-box>https://www.datature.io/blog/introduction-to-bytetrack-multi-object-tracking-by-associating-every-detection-box</a></p><p><a href=https://supervision.roboflow.com/trackers/>https://supervision.roboflow.com/trackers/</a></p></article></main><footer id=footer><div><span>Powered by <a class=link href=https://gohugo.io target=_blank rel=noopener>Hugo</a> |
Theme <a class=link href=https://github.com/michaelneuper/hugo-texify3 target=_blank rel=noopener>TeXify3</a></span></div><div><span>Copyright © 2025</span></div></footer></div><script src=https://www.tdj28.org/js/script.js defer></script></body></html>