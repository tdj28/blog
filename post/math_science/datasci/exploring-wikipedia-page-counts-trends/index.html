<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <meta name="generator" content="Hugo 0.101.0" />
  <link rel="canonical" href="http://3implieschaos.org/post/math_science/datasci/exploring-wikipedia-page-counts-trends/" />

  
    
    <meta name="description" content="There are some readily available tools in python for doing time series analysis, and these tools can be used to study Wikipedia page count stats.">
  

  <link rel="apple-touch-icon" sizes="180x180" href="http://3implieschaos.org/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="http://3implieschaos.org/favicon-32x32.png"> 
  <link rel="icon" type="image/png" sizes="16x16" href="http://3implieschaos.org/favicon-16x16.png"> 
  <link rel="manifest" href="http://3implieschaos.org/site.webmanifest"> 
  <link rel="mask-icon" href="http://3implieschaos.org/safari-pinned-tab.svg" color="#000000"> 
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="theme-color" content="#ffffff">

  <style>
    body {
      visibility: hidden;
      opacity: 0;
    }
  </style>

  <style id="darkTheme">
    .intro-and-nav,
    .main-and-footer {
      filter: invert(100%);
    }

    * {
      background-color: inherit
    }

    img:not([src*=".svg"]),
    .colors,
    iframe,
    .demo-container {
      filter: invert(100%);
    }
  </style>

  <link rel="stylesheet" href="/css/prism.css" media="none" onload="this.media='all';">

  
  
  <link rel="stylesheet" type="text/css" href="/css/styles.css">

  

  
  
  <title>Exploring Wikipedia Page Count Trends | tdj28</title>
</head>

  <body>
    <a href="#main">skip to content</a>
    <noscript>
  <style>
    body {
      visibility: visible;
      opacity: 1;
    }
  </style>
</noscript>

    <svg style="display: none">
  <symbol id="bookmark" viewBox="0 0 40 50">
   <g transform="translate(2266 3206.2)">
    <path style="stroke:currentColor;stroke-width:3.2637;fill:none" d="m-2262.2-3203.4-.2331 42.195 16.319-16.318 16.318 16.318.2331-42.428z"/>
   </g>
  </symbol>

  <symbol id="w3c" viewBox="0 0 127.09899 67.763">
   <text font-size="83" style="font-size:83px;font-family:Trebuchet;letter-spacing:-12;fill-opacity:0" letter-spacing="-12" y="67.609352" x="-26.782778">W3C</text>
   <text font-size="83" style="font-size:83px;font-weight:bold;font-family:Trebuchet;fill-opacity:0" y="67.609352" x="153.21722" font-weight="bold">SVG</text>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m33.695.377 12.062 41.016 12.067-41.016h8.731l-19.968 67.386h-.831l-12.48-41.759-12.479 41.759h-.832l-19.965-67.386h8.736l12.061 41.016 8.154-27.618-3.993-13.397h8.737z"/>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m91.355 46.132c0 6.104-1.624 11.234-4.862 15.394-3.248 4.158-7.45 6.237-12.607 6.237-3.882 0-7.263-1.238-10.148-3.702-2.885-2.47-5.02-5.812-6.406-10.022l6.82-2.829c1.001 2.552 2.317 4.562 3.953 6.028 1.636 1.469 3.56 2.207 5.781 2.207 2.329 0 4.3-1.306 5.909-3.911 1.609-2.606 2.411-5.738 2.411-9.401 0-4.049-.861-7.179-2.582-9.399-1.995-2.604-5.129-3.912-9.397-3.912h-3.327v-3.991l11.646-20.133h-14.062l-3.911 6.655h-2.493v-14.976h32.441v4.075l-12.31 21.217c4.324 1.385 7.596 3.911 9.815 7.571 2.22 3.659 3.329 7.953 3.329 12.892z"/>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m125.21 0 1.414 8.6-5.008 9.583s-1.924-4.064-5.117-6.314c-2.693-1.899-4.447-2.309-7.186-1.746-3.527.73-7.516 4.938-9.258 10.13-2.084 6.21-2.104 9.218-2.178 11.978-.115 4.428.58 7.043.58 7.043s-3.04-5.626-3.011-13.866c.018-5.882.947-11.218 3.666-16.479 2.404-4.627 5.954-7.404 9.114-7.728 3.264-.343 5.848 1.229 7.841 2.938 2.089 1.788 4.213 5.698 4.213 5.698l4.94-9.837z"/>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m125.82 48.674s-2.208 3.957-3.589 5.48c-1.379 1.524-3.849 4.209-6.896 5.555-3.049 1.343-4.646 1.598-7.661 1.306-3.01-.29-5.807-2.032-6.786-2.764-.979-.722-3.486-2.864-4.897-4.854-1.42-2-3.634-5.995-3.634-5.995s1.233 4.001 2.007 5.699c.442.977 1.81 3.965 3.749 6.572 1.805 2.425 5.315 6.604 10.652 7.545 5.336.945 9.002-1.449 9.907-2.031.907-.578 2.819-2.178 4.032-3.475 1.264-1.351 2.459-3.079 3.116-4.108.487-.758 1.276-2.286 1.276-2.286l-1.276-6.644z"/>
  </symbol>

  <symbol id="tag" viewBox="0 0 177.16535 177.16535">
    <g transform="translate(0 -875.2)">
     <path style="fill-rule:evenodd;stroke-width:0;fill:currentColor" d="m159.9 894.3-68.79 8.5872-75.42 77.336 61.931 60.397 75.429-76.565 6.8495-69.755zm-31.412 31.835a10.813 10.813 0 0 1 1.8443 2.247 10.813 10.813 0 0 1 -3.5174 14.872l-.0445.0275a10.813 10.813 0 0 1 -14.86 -3.5714 10.813 10.813 0 0 1 3.5563 -14.863 10.813 10.813 0 0 1 13.022 1.2884z"/>
    </g>
  </symbol>

  <symbol id="balloon" viewBox="0 0 141.73228 177.16535">
   <g transform="translate(0 -875.2)">
    <g>
     <path style="fill:currentColor" d="m68.156 882.83-.88753 1.4269c-4.9564 7.9666-6.3764 17.321-5.6731 37.378.36584 10.437 1.1246 23.51 1.6874 29.062.38895 3.8372 3.8278 32.454 4.6105 38.459 4.6694-.24176 9.2946.2879 14.377 1.481 1.2359-3.2937 5.2496-13.088 8.886-21.623 6.249-14.668 8.4128-21.264 10.253-31.252 1.2464-6.7626 1.6341-12.156 1.4204-19.764-.36325-12.93-2.1234-19.487-6.9377-25.843-2.0833-2.7507-6.9865-7.6112-7.9127-7.8436-.79716-.20019-6.6946-1.0922-6.7755-1.0248-.02213.0182-5.0006-.41858-7.5248-.22808l-2.149-.22808h-3.3738z"/>
     <path style="fill:currentColor" d="m61.915 883.28-3.2484.4497c-1.7863.24724-3.5182.53481-3.8494.63994-2.4751.33811-4.7267.86957-6.7777 1.5696-.28598 0-1.0254.20146-2.3695.58589-5.0418 1.4418-6.6374 2.2604-8.2567 4.2364-6.281 7.6657-11.457 18.43-12.932 26.891-1.4667 8.4111.71353 22.583 5.0764 32.996 3.8064 9.0852 13.569 25.149 22.801 37.517 1.3741 1.841 2.1708 2.9286 2.4712 3.5792 3.5437-1.1699 6.8496-1.9336 10.082-2.3263-1.3569-5.7831-4.6968-21.86-6.8361-33.002-.92884-4.8368-2.4692-14.322-3.2452-19.991-.68557-5.0083-.77707-6.9534-.74159-15.791.04316-10.803.41822-16.162 1.5026-21.503 1.4593-5.9026 3.3494-11.077 6.3247-15.852z"/>
     <path style="fill:currentColor" d="m94.499 885.78c-.10214-.0109-.13691 0-.0907.0409.16033.13489 1.329 1.0675 2.5976 2.0723 6.7003 5.307 11.273 14.568 12.658 25.638.52519 4.1949.24765 14.361-.5059 18.523-2.4775 13.684-9.7807 32.345-20.944 53.519l-3.0559 5.7971c2.8082.76579 5.7915 1.727 8.9926 2.8441 11.562-11.691 18.349-19.678 24.129-28.394 7.8992-11.913 11.132-20.234 12.24-31.518.98442-10.02-1.5579-20.876-6.7799-28.959-.2758-.4269-.57803-.86856-.89617-1.3166-3.247-6.13-9.752-12.053-21.264-16.131-2.3687-.86369-6.3657-2.0433-7.0802-2.1166z"/>
     <path style="fill:currentColor" d="m32.52 892.22c-.20090-.13016-1.4606.81389-3.9132 2.7457-11.486 9.0476-17.632 24.186-16.078 39.61.79699 7.9138 2.4066 13.505 5.9184 20.562 5.8577 11.77 14.749 23.219 30.087 38.74.05838.059.12188.1244.18052.1838 1.3166-.5556 2.5965-1.0618 3.8429-1.5199-.66408-.32448-1.4608-1.3297-3.8116-4.4602-5.0951-6.785-8.7512-11.962-13.051-18.486-5.1379-7.7948-5.0097-7.5894-8.0586-13.054-6.2097-11.13-8.2674-17.725-8.6014-27.563-.21552-6.3494.13041-9.2733 1.775-14.987 2.1832-7.5849 3.9273-10.986 9.2693-18.07 1.7839-2.3656 2.6418-3.57 2.4409-3.7003z"/>
     <path style="fill:currentColor" d="m69.133 992.37c-6.2405.0309-12.635.76718-19.554 2.5706 4.6956 4.7759 9.935 10.258 12.05 12.625l4.1272 4.6202h11.493l3.964-4.4516c2.0962-2.3541 7.4804-7.9845 12.201-12.768-8.378-1.4975-16.207-2.6353-24.281-2.5955z"/>
     <rect style="stroke-width:0;fill:currentColor" ry="2.0328" height="27.746" width="22.766" y="1017.7" x="60.201"/>
    </g>
   </g>
  </symbol>

  <symbol id="info" viewBox="0 0 41.667 41.667">
   <g transform="translate(-37.035 -1004.6)">
    <path style="stroke-linejoin:round;stroke:currentColor;stroke-linecap:round;stroke-width:3.728;fill:none" d="m76.25 1030.2a18.968 18.968 0 0 1 -23.037 13.709 18.968 18.968 0 0 1 -13.738 -23.019 18.968 18.968 0 0 1 23.001 -13.768 18.968 18.968 0 0 1 13.798 22.984"/>
    <g transform="matrix(1.1146 0 0 1.1146 -26.276 -124.92)">
     <path style="stroke:currentColor;stroke-linecap:round;stroke-width:3.728;fill:none" d="m75.491 1039.5v-8.7472"/>
     <path style="stroke-width:0;fill:currentColor" transform="scale(-1)" d="m-73.193-1024.5a2.3719 2.3719 0 0 1 -2.8807 1.7142 2.3719 2.3719 0 0 1 -1.718 -2.8785 2.3719 2.3719 0 0 1 2.8763 -1.7217 2.3719 2.3719 0 0 1 1.7254 2.8741"/>
    </g>
   </g>
  </symbol>

  <symbol id="warning" viewBox="0 0 48.430474 41.646302">
    <g transform="translate(-1.1273 -1010.2)">
     <path style="stroke-linejoin:round;stroke:currentColor;stroke-linecap:round;stroke-width:4.151;fill:none" d="m25.343 1012.3-22.14 37.496h44.28z"/>
     <path style="stroke:currentColor;stroke-linecap:round;stroke-width:4.1512;fill:none" d="m25.54 1027.7v8.7472"/>
     <path style="stroke-width:0;fill:currentColor" d="m27.839 1042.8a2.3719 2.3719 0 0 1 -2.8807 1.7143 2.3719 2.3719 0 0 1 -1.718 -2.8785 2.3719 2.3719 0 0 1 2.8763 -1.7217 2.3719 2.3719 0 0 1 1.7254 2.8741"/>
    </g>
  </symbol>

  <symbol id="menu" viewBox="0 0 50 50">
     <rect style="stroke-width:0;fill:currentColor" height="10" width="50" y="0" x="0"/>
     <rect style="stroke-width:0;fill:currentColor" height="10" width="50" y="20" x="0"/>
     <rect style="stroke-width:0;fill:currentColor" height="10" width="50" y="40" x="0"/>
   </symbol>

   <symbol id="link" viewBox="0 0 50 50">
    <g transform="translate(0 -1002.4)">
     <g transform="matrix(.095670 0 0 .095670 2.3233 1004.9)">
      <g>
       <path style="stroke-width:0;fill:currentColor" d="m452.84 192.9-128.65 128.65c-35.535 35.54-93.108 35.54-128.65 0l-42.881-42.886 42.881-42.876 42.884 42.876c11.845 11.822 31.064 11.846 42.886 0l128.64-128.64c11.816-11.831 11.816-31.066 0-42.9l-42.881-42.881c-11.822-11.814-31.064-11.814-42.887 0l-45.928 45.936c-21.292-12.531-45.491-17.905-69.449-16.291l72.501-72.526c35.535-35.521 93.136-35.521 128.64 0l42.886 42.881c35.535 35.523 35.535 93.141-.001 128.66zm-254.28 168.51-45.903 45.9c-11.845 11.846-31.064 11.817-42.881 0l-42.884-42.881c-11.845-11.821-11.845-31.041 0-42.886l128.65-128.65c11.819-11.814 31.069-11.814 42.884 0l42.886 42.886 42.876-42.886-42.876-42.881c-35.54-35.521-93.113-35.521-128.65 0l-128.65 128.64c-35.538 35.545-35.538 93.146 0 128.65l42.883 42.882c35.51 35.54 93.11 35.54 128.65 0l72.496-72.499c-23.956 1.597-48.092-3.784-69.474-16.283z"/>
      </g>
     </g>
    </g>
  </symbol>

  <symbol id="doc" viewBox="0 0 35 45">
   <g transform="translate(-147.53 -539.83)">
    <path style="stroke:currentColor;stroke-width:2.4501;fill:none" d="m149.38 542.67v39.194h31.354v-39.194z"/>
    <g style="stroke-width:25" transform="matrix(.098003 0 0 .098003 133.69 525.96)">
     <path d="m220 252.36h200" style="stroke:currentColor;stroke-width:25;fill:none"/>
     <path style="stroke:currentColor;stroke-width:25;fill:none" d="m220 409.95h200"/>
     <path d="m220 488.74h200" style="stroke:currentColor;stroke-width:25;fill:none"/>
     <path d="m220 331.15h200" style="stroke:currentColor;stroke-width:25;fill:none"/>
    </g>
   </g>
 </symbol>

 <symbol id="tick" viewBox="0 0 177.16535 177.16535">
  <g transform="translate(0 -875.2)">
   <rect style="stroke-width:0;fill:currentColor" transform="rotate(30)" height="155" width="40" y="702.99" x="556.82"/>
   <rect style="stroke-width:0;fill:currentColor" transform="rotate(30)" height="40" width="90.404" y="817.99" x="506.42"/>
  </g>
 </symbol>
</svg>

    <div class="wrapper">
      <header class="intro-and-nav" role="banner">
  <div>
    <div class="intro">
      <a
        class="logo"
        href="http://3implieschaos.org/"
        aria-label="tdj28 home page"
      >
        
          <h1>tdj28</h1>
        
      </a>
      <p class="library-desc">
         Potentially helpful notes, tips, and how-tos. 
      </p>
    </div>
    <nav id="patterns-nav" class="patterns" role="navigation">
  <h2 class="vh">Main navigation</h2>
  <button id="menu-button" aria-expanded="false">
    <svg viewBox="0 0 50 50" aria-hidden="true" focusable="false">
      <use href="#menu"></use>
    </svg>
    Menu
  </button>
  
  <ul id="patterns-list">
  
    <li class="pattern">
      
      
      
      
      <a href="/" >
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use href="#bookmark"></use>
        </svg>
        <span class="text">Home</span>
      </a>
    </li>
  
    <li class="pattern">
      
      
      
      
      <a href="/post/" aria-current="page">
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use href="#bookmark"></use>
        </svg>
        <span class="text">Blog</span>
      </a>
    </li>
  
    <li class="pattern">
      
      
      
      
      <a href="/tags/" >
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use href="#bookmark"></use>
        </svg>
        <span class="text">Tags</span>
      </a>
    </li>
  
    <li class="pattern">
      
      
      
      
      <a href="/about/" >
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use href="#bookmark"></use>
        </svg>
        <span class="text">About</span>
      </a>
    </li>
  
    <li class="pattern">
      
      
      
      
      <a href="/physics/" >
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use href="#bookmark"></use>
        </svg>
        <span class="text">Physics</span>
      </a>
    </li>
  
    <li class="pattern">
      
      
      
      
      <a href="/index.xml" >
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use href="#bookmark"></use>
        </svg>
        <span class="text">RSS</span>
      </a>
    </li>
  
  </ul>
</nav>
    
  </div>
</header>

      <div class="main-and-footer">
        <div>
          
  <main id="main">
    <h1>
      <svg class="bookmark-icon" aria-hidden="true" viewBox="0 0 40 50" focusable="false">
        <use href="#bookmark"></use>
      </svg>
      Exploring Wikipedia Page Count Trends
    </h1>

    <div class="date">
      
      
      <strong>Publish date: </strong>Aug 5, 2018
      
        
          <br>
          <strong>Last updated: </strong>Jul 23, 2022
        
      
    </div>

    
      <div class="tags">
        <strong>Tags: </strong>
        <ul aria-label="tags">
          
            <li>
              <svg class="tag-icon" aria-hidden="true" viewBox="0 0 177.16535 177.16535" focusable="false">
                <use href="#tag"></use>
              </svg>
              
              <a href="/tags/timeseries/">timeseries</a>
            </li>
          
            <li>
              <svg class="tag-icon" aria-hidden="true" viewBox="0 0 177.16535 177.16535" focusable="false">
                <use href="#tag"></use>
              </svg>
              
              <a href="/tags/wiki/">wiki</a>
            </li>
          
            <li>
              <svg class="tag-icon" aria-hidden="true" viewBox="0 0 177.16535 177.16535" focusable="false">
                <use href="#tag"></use>
              </svg>
              
              <a href="/tags/data-science/">data-science</a>
            </li>
          
            <li>
              <svg class="tag-icon" aria-hidden="true" viewBox="0 0 177.16535 177.16535" focusable="false">
                <use href="#tag"></use>
              </svg>
              
              <a href="/tags/python/">python</a>
            </li>
          
            <li>
              <svg class="tag-icon" aria-hidden="true" viewBox="0 0 177.16535 177.16535" focusable="false">
                <use href="#tag"></use>
              </svg>
              
              <a href="/tags/statistics/">statistics</a>
            </li>
          
        </ul>
      </div>
    

    
  <nav class="toc" aria-labelledby="toc-heading">
    <strong id="toc-heading">Table of Contents</strong>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#additive-models-for-seasonality-decomposition-a-quick-primer">Additive models for seasonality decomposition, a quick primer</a></li>
    <li><a href="#wikipedia-page-hit-stats">Wikipedia Page hit stats</a></li>
    <li><a href="#conclusions">Conclusions</a></li>
  </ul>
</nav>
  </nav>



    <h1 id="exploring-wikipedia-page-counts-via-additive-models-for-seasonality-decomposition">Exploring Wikipedia page counts via additive models for seasonality decomposition</h1>
<h2 id="introduction">Introduction</h2>
<p>Wikipedia, in addition to being quite valuable as a <em>starting</em> point for many student essays (as somebody who has spent time in front of the classroom, I can&rsquo;t emphasize the word <em>starting</em> enough here), can provide some sociological insight by providing page count hits. In this brief blog entry, we will explore two python-ready implementations of additive models for seasonality decomposition in the context of the following topic:</p>
<ul>
<li>Is there any seasonality with wikipedia page hits? For this question, we will look at a few keywords which we think are quite often used by school students in researching for common essay questions (e.g. Abraham_Lincoln) and other keywords which are less likely to be commonly used by students for essays at any level, for example, the American telecommunications company Sprint.</li>
</ul>
<p>This blog entry is posted in the form of a Jupyter Notebook so that readers can recreate the findings and pursue further questions more easily.</p>
<p>We use two <em>additive model</em> implementations, one from a library called <a href="https://www.statsmodels.org/stable/index.html">statsmodel</a> and another from a library developed by Facebook called <a href="https://facebook.github.io/prophet/">prophet</a>.</p>
<h2 id="additive-models-for-seasonality-decomposition-a-quick-primer">Additive models for seasonality decomposition, a quick primer</h2>
<p>Let&rsquo;s begin by creating a artificial time series.</p>
<p>Before importing pandas, numpy, etc., I want to turn off some typical warnings that we see from these libraries. This is just to keep the output looking clean for presentation purposes.</p>
<pre><code class="language-python">import warnings
warnings.filterwarnings(&quot;ignore&quot;, message=&quot;numpy.dtype size changed&quot;)
warnings.filterwarnings(&quot;ignore&quot;, message=&quot;numpy.ufunc size changed&quot;)
warnings.filterwarnings(&quot;ignore&quot;,category=FutureWarning)
</code></pre>
<p>Next, we import all of the great Python libraries. Here, for seasonal decomposition we are using statsmodel and Facebook&rsquo;s Prophet.</p>
<pre><code class="language-python">import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import datetime
%matplotlib inline
from matplotlib.pylab import rcParams
import seaborn as sns
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.seasonal import seasonal_decompose
from fbprophet import Prophet

rcParams['figure.figsize'] = 16, 7
</code></pre>
<p>Next, let&rsquo;s create a fake data set.</p>
<pre><code class="language-python">entries = 365 * 2 # Two years worth of days
df = pd.DataFrame(np.random.randn(entries)).cumsum()
df.head()
plt.plot(df[0].tolist())
plt.show()
</code></pre>
<p><img src="assets/assets20180805/output_7_0.png" alt="png"></p>
<p>Our brains have pattern-matching algorithms trained over billions of years, so even though the above data set is a random walk, we may see patterns there anyway. If we run it again, those patterns will change even though we were using the exact same algorithm to generate them. This of course doesn&rsquo;t imply that finding patterns in data is an empty task, there is very often patterns that are legitimate. The point here is to show how the additive model works by throwing something known to be random at it. Just to show, again, how entirely random the generated dataset is, let&rsquo;s throw a bunch in the same graph:</p>
<pre><code class="language-python">def rwts(entries=100):
    _df = pd.DataFrame(np.random.randn(entries)).cumsum()
    start = datetime.datetime.strptime(&quot;20160101&quot;, &quot;%Y%d%m&quot;)
    dates_generated = [start + datetime.timedelta(days=x) for x in range(0, entries)]
    dtse = pd.Series(dates_generated)
    _df['ds'] = dtse
    _df = _df.rename(columns={0: &quot;y&quot;})
    _df.index = _df['ds']
    return _df
</code></pre>
<pre><code class="language-python">entries = 365 * 2 # Two years worth of days
rwdf = []
for i in range(0, 10):
    rwdf.append(rwts(entries))
    plt.plot(rwdf[i]['y']) #.tolist())

plt.show()
</code></pre>
<p><img src="assets/assets20180805/output_10_0.png" alt="png"></p>
<p>Next, let&rsquo;s see what happens when we apply the statsmodel implementation of the additive model to a random walk dataset:</p>
<pre><code class="language-python">def additive_seasonal_plot(_df, frequency=365, title=&quot;I forgot to tinclude a title.&quot;):
    fig, ax = plt.subplots()
    plt.title(title)
    decompositionm = seasonal_decompose(_df, freq=frequency, model='additive')
    trendm = decompositionm.trend
    seasonalm = decompositionm.seasonal
    residualm = decompositionm.resid
    plt.subplot(411)
    plt.plot(_df, label='Original')
    plt.legend(loc='best')
    plt.subplot(412)
    plt.plot(trendm, label='Trend')
    plt.legend(loc='best')
    plt.subplot(413)
    plt.plot(seasonalm,label='Seasonality')
    plt.legend(loc='best')
    plt.subplot(414)
    plt.plot(residualm, label='Residuals')
    plt.legend(loc='best')
    plt.tight_layout()
</code></pre>
<pre><code class="language-python">additive_seasonal_plot(rwts(365*2)['y'], frequency=365, title=&quot;Random Walk&quot;)
</code></pre>
<p><img src="assets/assets20180805/output_13_0.png" alt="png"></p>
<p>Now let&rsquo;s try that with Prophet:</p>
<pre><code class="language-python">def prophet_seasonal_plot(_df, frequency=365, mytitle=&quot;I forgot to tinclude a title.&quot;):
    _m = Prophet(yearly_seasonality = True, daily_seasonality=False, weekly_seasonality = True, mcmc_samples = 0, seasonality_prior_scale=50)
    _df['y'].plot(title=mytitle)
    _m.fit(_df)
    _future = _m.make_future_dataframe(periods=365)
    _forecast = _m.predict(future)
    _m.plot_components(_forecast);
    _m.plot(_forecast);
</code></pre>
<pre><code class="language-python">prophet_seasonal_plot(rwts(365*2), frequency=365, mytitle=&quot;Random Walk&quot;)
</code></pre>
<p><img src="assets/assets20180805/output_16_0.png" alt="png"></p>
<p><img src="assets/assets20180805/output_16_1.png" alt="png"></p>
<p><img src="assets/assets20180805/output_16_2.png" alt="png"></p>
<p>Prophet makes nicer graphs out of the box, for sure. It also has a nice way to show uncertainty. And looking at the above, you might very well believe that indeed we have found some sort of phenomenon that seems to peak in late winter and spring, and on Thursday for some reason. It would be a pretty safe bet to bet that the above trend would peak in the months following the last dataset we have, right? Wrong, of course, because as you know, this dataset was generated entirely randomly. The lesson here is not that this method for modeling seasonality and forecasting is wrong, as indeed they work exactly as they are designed to, but instead that we need to be quite careful not to so readily believe what they say. This is the giant grain of salt I&rsquo;m putting on your plate before getting to the fun stuff.</p>
<p>To make this point entirely visual, let&rsquo;s do the same analysis as above, but instead of just using two years worth of fake data, let&rsquo;s create three years, but only feed the additive model two years, and see how it does in the third year.</p>
<pre><code class="language-python">df1 = rwts(365*3)
mask1 = (df1['ds'] &gt;= '20160101') &amp; (df1['ds'] &lt; '20180101')
df2 = df1.loc[mask1]
mask2 = (df1['ds'] &gt;= '20180101') &amp; (df1['ds'] &lt; '20190101')
df3 = df1.loc[mask2]
_m = Prophet(yearly_seasonality = True, daily_seasonality=False,
             weekly_seasonality = True, mcmc_samples = 0, seasonality_prior_scale=50)
_m.fit(df2)
_future = _m.make_future_dataframe(periods=365)
_forecast = _m.predict(future)
_m.plot(_forecast);
</code></pre>
<p><img src="assets/assets20180805/output_18_0.png" alt="png"></p>
<p>That looks great, that stock is about to go up like crazy, let&rsquo;s dump our entire life-savings into that stock!</p>
<pre><code class="language-python">_m.plot(_forecast);
df3['y'].plot(color='Red')
</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f7fbe8d1048&gt;
</code></pre>
<p><img src="assets/assets20180805/output_20_1.png" alt="png"></p>
<p>Oops.</p>
<h2 id="wikipedia-page-hit-stats">Wikipedia Page hit stats</h2>
<p>Previously, in order to get a nice way to access Wikipedia page hit data, I would have suggsted the R library wikipediatrend. The situation has evolved such that wikipediatrend is not functional (see <a href="https://github.com/petermeissner/wikipediatrend/issues/32">this link for more details</a>). Fortunately, Wikimedia themselves have released an api that has a <a href="https://github.com/mediawiki-utilities/python-mwviews">python library</a>.</p>
<pre><code class="language-python">from mwviews.api import PageviewsClient

p = PageviewsClient('blog')
</code></pre>
<p>Although there is a <a href="https://dumps.wikimedia.org/other/pagecounts-raw/">repository</a> of old pageviews pre-dating July 2015, the API only provides dates from July 2015 forward. Let&rsquo;s get three years worth of data from July 2015 to July 2018. The following command outputs a dictionary with items of the form:</p>
<pre><code> datetime.datetime(2015, 12, 21, 0, 0): {'Lincoln': 503},
</code></pre>
<p>when we make a call to extract page hit counts for the topic &lsquo;Abraham Lincoln&rsquo;.</p>
<pre><code class="language-python">dictLincoln = p.article_views('en.wikipedia', ['Abraham Lincoln'], granularity='daily', start='20150701', end='20180701');
</code></pre>
<pre><code class="language-python">dfLincoln = pd.DataFrame.from_dict(dictLincoln).transpose()
</code></pre>
<pre><code class="language-python">dfLincoln.index = pd.to_datetime(dfLincoln.index)
dfLincoln = dfLincoln.rename(columns={&quot;Abraham_Lincoln&quot;: &quot;Daily Page Counts&quot;})
dfLincoln.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Daily Page Counts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2015-07-01</th>
      <td>15223</td>
    </tr>
    <tr>
      <th>2015-07-02</th>
      <td>15137</td>
    </tr>
    <tr>
      <th>2015-07-03</th>
      <td>17291</td>
    </tr>
    <tr>
      <th>2015-07-04</th>
      <td>19697</td>
    </tr>
    <tr>
      <th>2015-07-05</th>
      <td>18149</td>
    </tr>
  </tbody>
</table>
</div>
<p>Do we see any trends just by glancing at the plot of these page hits over the three year period from July 2015 to July 2018? Initially we may see a few, such as that the page hits seem to go up after January, and have some unusual peaks in late 2016 and early 2017 (very likely, and precisely as we will see later, related to the election and inauguration of that period).</p>
<pre><code class="language-python">dfLincoln.plot(title=&quot;Abraham Lincoln Wiki Page Hits&quot;)
</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f7fc8603a90&gt;
</code></pre>
<p><img src="assets/assets20180805/output_29_1.png" alt="png"></p>
<p>In fact, let&rsquo;s plot key dates on that plot, such as the US election of 2016, inauguration of 2017, President&rsquo;s Day holidays, and the 4th of July. These key dates explain almost all of the spikes.</p>
<pre><code class="language-python">ax = dfLincoln.plot(title=&quot;Abraham Lincoln Wiki Page Hits + Key dates&quot;, linewidth=3.0);
important_dates = ['2016-11-08', '2017-01-20', '2016-02-15', '2017-02-20', '2018-02-19',
                   '2015-07-04', '2016-07-04', '2017-07-04', '2018-07-04']
for xc in important_dates:
    plt.axvline(x=xc, color='k', linestyle='--')
ax.set_xlim(pd.Timestamp('2016-01-01'), pd.Timestamp('2018-03-01'))
ax.set_ylim(0, 90000)
</code></pre>
<pre><code>(0, 90000)
</code></pre>
<p><img src="assets/assets20180805/output_31_1.png" alt="png"></p>
<p>Next we apply statsmodel&rsquo;s implementation of the additive model for seasonal decomposition:</p>
<pre><code class="language-python">fig, ax = plt.subplots()
plt.title('Seasonal trend for Wiki Page Counts: Abraham Lincoln')
decompositionm = seasonal_decompose(dfLincoln, freq=365, model='additive')
trendm = decompositionm.trend
seasonalm = decompositionm.seasonal
residualm = decompositionm.resid
plt.subplot(411)
plt.plot(dfLincoln, label='Original')
plt.legend(loc='best')
plt.subplot(412)
plt.plot(trendm, label='Trend')
plt.legend(loc='best')
plt.subplot(413)
plt.plot(seasonalm,label='Seasonality')
plt.legend(loc='best')
plt.subplot(414)
plt.plot(residualm, label='Residuals')
plt.legend(loc='best')
plt.tight_layout()
</code></pre>
<p><img src="assets/assets20180805/output_33_0.png" alt="png"></p>
<p>This model has identified a trend increase in election year 2016, which seems to make sense. However, it overfit the spike seen around election day 2016, and we can see the result of that overfit in the residuals which dip extremely a year before and after election day. In a future blog post, we will look at working around this by marking the key dates as holidays so that the algorithm doesn&rsquo;t overfit those days. The seasonality trend has also found something pretty expected, which is that hits on that page seem to breathe with the typical American school year. That is, we can see in the seasonal trends that there are many students using Wikipedia (hopefully as a starting point and not a primary resource) for essay papers and homework answers on Abraham Lincoln.</p>
<pre><code class="language-python">ax = seasonalm.plot(title=&quot;Abraham Lincoln Wiki Page Hits Seasonal Trend + Key dates + Shaded School Year&quot;, linewidth=3.0);
important_dates = ['2016-11-08', '2017-01-20', '2016-02-15', '2017-02-20', '2018-02-19',
                   '2015-12-25', '2016-12-25', '2017-12-25',
                   '2015-07-04', '2016-07-04', '2017-07-04', '2018-07-04']
for xc in important_dates:
    ax.axvline(x=xc, color='k', linestyle='--')
ax.axvspan(pd.Timestamp('2015-09-01'), pd.Timestamp('2016-06-01'), facecolor='g', alpha=0.3)
ax.axvspan(pd.Timestamp('2016-09-01'), pd.Timestamp('2017-06-01'), facecolor='g', alpha=0.3)
ax.axvspan(pd.Timestamp('2017-09-01'), pd.Timestamp('2018-06-01'), facecolor='g', alpha=0.3)

ax.set_xlim(pd.Timestamp('2015-07-01'), pd.Timestamp('2018-03-01'))
ax.set_ylim(-10000, 40000)
</code></pre>
<pre><code>(-10000, 40000)
</code></pre>
<p><img src="assets/assets20180805/output_35_1.png" alt="png"></p>
<p>Zooming in on the residuals, we see again how the overfitting to the special events (election and inauguration) hurt the accuracy of the models.</p>
<pre><code class="language-python">ax = residualm.plot(title=&quot;Abraham Lincoln Wiki Page Hits Seasonal Residuals + Key dates&quot;, linewidth=3.0);
important_dates = [ '2016-01-20', '2016-11-08', '2017-01-20', '2017-11-08']
for xc in important_dates:
    ax.axvline(x=xc, color='k', linestyle='--')
ax.set_xlim(pd.Timestamp('2015-12-01'), pd.Timestamp('2018-02-01'))
ax.set_ylim(-40000, 40000)
</code></pre>
<pre><code>(-40000, 40000)
</code></pre>
<p><img src="assets/assets20180805/output_37_1.png" alt="png"></p>
<p>Now we have stated a hypothesis without backing it up, namely that the seasonality over the year in page hits for the Wikipedia entry for Abraham Lincoln reflects the patterns of the American school year. This is pretty impossible to prove without data that is impossible or not practical to obtain, namely we would have to have the IP addresses of all those page hits and tie those in to schools and households with students, etc. Never going to happen. But we can strengthen our confidence in our hypothesis by testing it in the negative, that is, what will we see if we pick a topic which we do <em>not</em> expect to be tied to school-year patterns, a topic students would rarely ever look up for school work? Let&rsquo;s try the American telecom Sprint.</p>
<pre><code class="language-python">def get_wiki_df(topic, ymin, ymax):
    _dict = p.article_views('en.wikipedia', [topic], granularity='daily', start='20150701', end='20180701');
    _df = pd.DataFrame.from_dict(_dict).transpose()
    _df.index = pd.to_datetime(_df.index)
    _df = _df.rename(columns={topic: &quot;Daily Page Counts&quot;})
    ax = _df.plot(title=&quot;{} Wiki Page Hits + Key dates + Shaded School Year&quot;.format(topic), linewidth=3.0);
    important_dates = ['2016-11-08', '2017-01-20', '2016-02-15', '2017-02-20', '2018-02-19',
                       '2015-12-25', '2016-12-25', '2017-12-25',
                       '2015-07-04', '2016-07-04', '2017-07-04', '2018-07-04']
    for xc in important_dates:
        ax.axvline(x=xc, color='k', linestyle='--')
    ax.axvspan(pd.Timestamp('2015-09-01'), pd.Timestamp('2016-06-01'), facecolor='g', alpha=0.3)
    ax.axvspan(pd.Timestamp('2016-09-01'), pd.Timestamp('2017-06-01'), facecolor='g', alpha=0.3)
    ax.axvspan(pd.Timestamp('2017-09-01'), pd.Timestamp('2018-06-01'), facecolor='g', alpha=0.3)

    ax.set_xlim(pd.Timestamp('2015-07-01'), pd.Timestamp('2018-03-01'))
    ax.set_ylim(ymin, ymax)
    return _df

def get_wiki_seasonal(topic, ymin, ymax):
    _dict = p.article_views('en.wikipedia', [topic], granularity='daily', start='20150701', end='20180701');
    _df = pd.DataFrame.from_dict(_dict).transpose()
    _df.index = pd.to_datetime(_df.index)
    _df = _df.rename(columns={topic: &quot;Daily Page Counts&quot;})
    decompositionm = seasonal_decompose(_df, freq=365, model='additive')
    seasonalm = decompositionm.seasonal
    ax = seasonalm.plot(title=&quot;{} Wiki Page Hits Seasonal Trend + Key dates + Shaded School Year&quot;.format(topic), linewidth=3.0);
    important_dates = ['2016-11-08', '2017-01-20', '2016-02-15', '2017-02-20', '2018-02-19',
                       '2015-12-25', '2016-12-25', '2017-12-25',
                       '2015-07-04', '2016-07-04', '2017-07-04', '2018-07-04']
    for xc in important_dates:
        ax.axvline(x=xc, color='k', linestyle='--')
    ax.axvspan(pd.Timestamp('2015-09-01'), pd.Timestamp('2016-06-01'), facecolor='g', alpha=0.3)
    ax.axvspan(pd.Timestamp('2016-09-01'), pd.Timestamp('2017-06-01'), facecolor='g', alpha=0.3)
    ax.axvspan(pd.Timestamp('2017-09-01'), pd.Timestamp('2018-06-01'), facecolor='g', alpha=0.3)

    ax.set_xlim(pd.Timestamp('2015-07-01'), pd.Timestamp('2018-03-01'))
    ax.set_ylim(ymin, ymax)
    return _df
</code></pre>
<pre><code class="language-python">ax=get_wiki_df(&quot;Sprint&quot;, 0, 400)
ax=get_wiki_seasonal(&quot;Sprint&quot;, -100, 400)
</code></pre>
<p><img src="assets/assets20180805/output_40_0.png" alt="png"></p>
<p><img src="assets/assets20180805/output_40_1.png" alt="png"></p>
<p>The seasonality trend is scarred by incorporating a singular spike in data (the additive model tries to balance bias and variance, but obviously both can break at the same time), but we see no pattern tied to the school year. (One flaw is that the hits on the Sprint wiki page are much lower to begin with, so it isn&rsquo;t as reliable of a statement.) Let&rsquo;s try another topic which we suspect should breathe with the school year, US President George Washington.</p>
<pre><code class="language-python">ax=get_wiki_df(&quot;George Washington&quot;, 0, 80000)
ax=get_wiki_seasonal(&quot;George Washington&quot;, -20000, 60000)
</code></pre>
<p><img src="assets/assets20180805/output_42_0.png" alt="png"></p>
<p><img src="assets/assets20180805/output_42_1.png" alt="png"></p>
<p>The trend here is less pronounced, but still evident. While we are on the topic, we present below, without commentary, a comparison on page hits between Donald Trump and Bill Clinton. I present both on the same scale to show the extraordinary difference in the magnitude of public interest in each individual.</p>
<pre><code class="language-python">ax=get_wiki_df(&quot;Donald Trump&quot;, 0, 7000000)
ax=get_wiki_seasonal(&quot;Donald Trump&quot;, -200000, 5000000)
</code></pre>
<p><img src="assets/assets20180805/output_44_0.png" alt="png"></p>
<p><img src="assets/assets20180805/output_44_1.png" alt="png"></p>
<pre><code class="language-python">ax=get_wiki_df(&quot;Bill Clinton&quot;, 0, 7000000)
ax=get_wiki_seasonal(&quot;Bill Clinton&quot;, -200000, 5000000)
</code></pre>
<p><img src="assets/assets20180805/output_45_0.png" alt="png"></p>
<p><img src="assets/assets20180805/output_45_1.png" alt="png"></p>
<p>Let&rsquo;s make use of Prophet now, because it has nicer graphs and seems a little more robust in my limited usage so far. We&rsquo;ve used it above, but I will walk through a little more slowly this time. First we must create a Prophet object, and fit our dataframe to Prophet such that there is a datetime column labeled ds, and the counts value column is relabeled y.</p>
<pre><code class="language-python">m = Prophet(yearly_seasonality = True, weekly_seasonality = True, mcmc_samples = 0, seasonality_prior_scale=50)
proLincoln = dfLincoln
proLincoln['ds'] = dfLincoln.index
proLincoln.head()

</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Daily Page Counts</th>
      <th>ds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2015-07-01</th>
      <td>15223</td>
      <td>2015-07-01</td>
    </tr>
    <tr>
      <th>2015-07-02</th>
      <td>15137</td>
      <td>2015-07-02</td>
    </tr>
    <tr>
      <th>2015-07-03</th>
      <td>17291</td>
      <td>2015-07-03</td>
    </tr>
    <tr>
      <th>2015-07-04</th>
      <td>19697</td>
      <td>2015-07-04</td>
    </tr>
    <tr>
      <th>2015-07-05</th>
      <td>18149</td>
      <td>2015-07-05</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">proLincoln = proLincoln.rename(columns={'Daily Page Counts': 'y'})
proLincoln.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>y</th>
      <th>ds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2015-07-01</th>
      <td>15223</td>
      <td>2015-07-01</td>
    </tr>
    <tr>
      <th>2015-07-02</th>
      <td>15137</td>
      <td>2015-07-02</td>
    </tr>
    <tr>
      <th>2015-07-03</th>
      <td>17291</td>
      <td>2015-07-03</td>
    </tr>
    <tr>
      <th>2015-07-04</th>
      <td>19697</td>
      <td>2015-07-04</td>
    </tr>
    <tr>
      <th>2015-07-05</th>
      <td>18149</td>
      <td>2015-07-05</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">m.fit(proLincoln)
</code></pre>
<pre><code>INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.
/home/d7082791602/.local/lib/python3.6/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  elif np.issubdtype(np.asarray(v).dtype, float):





&lt;fbprophet.forecaster.Prophet at 0x7f7fbdf32cc0&gt;
</code></pre>
<pre><code class="language-python">future = m.make_future_dataframe(periods=365)
forecast = m.predict(future)
forecast.head()
m.plot_components(forecast);
m.plot(forecast);
</code></pre>
<p><img src="assets/assets20180805/output_50_0.png" alt="png"></p>
<p><img src="assets/assets20180805/output_50_1.png" alt="png"></p>
<p>Here we see that prophet also very nicely picks out the 2016 trend, and clearly picks out the school year trend as well as the weekday trend. In order to make these quick peaks at the data more systematic, we create and use the following function. We then use these functions to take a look at a varied array of Wikipedia pages and conjecture a bit about the results.</p>
<p>The first one we take a look at is &ldquo;Christmas&rdquo; which we expect, and indeed find, has a very clean seasonality. Note the weekday trend line shows a preference for some days over others, which is an artifact simply of which day the holiday fell on in the years that are used for training (since this holiday doesn&rsquo;t fall on any particular weekday by design, and we only trained based on three years, those three days in occured on, or rather Christmas Eve, will see the bias. That would be Thursday/Friday 2015, Sunday/Monday 2016, and Monday/Tuesday 2017 [2016 was a leap year]).</p>
<pre><code class="language-python">def prophet_wiki_df(topic, starting='20150701', ending='20180804'):
    _m = Prophet(yearly_seasonality = True, daily_seasonality=False, weekly_seasonality = True, mcmc_samples = 0, seasonality_prior_scale=50)
    _dict = p.article_views('en.wikipedia', [topic], granularity='daily', start=starting, end=ending);
    _df = pd.DataFrame.from_dict(_dict).transpose()
    _df.index = pd.to_datetime(_df.index)
    _df.plot(title=&quot;{} Wikipedia Page Hit Counts&quot;.format(topic))
    _df = _df.rename(columns={topic.replace(&quot; &quot;, &quot;_&quot;): &quot;y&quot;})
    _df['ds'] = _df.index
    _m.fit(_df)
    _future = _m.make_future_dataframe(periods=365)
    _forecast = _m.predict(future)
    _m.plot_components(_forecast);
    _m.plot(_forecast);
</code></pre>
<pre><code class="language-python">prophet_wiki_df('Christmas')
</code></pre>
<p><img src="assets/assets20180805/output_53_0.png" alt="png"></p>
<p><img src="assets/assets20180805/output_53_1.png" alt="png"></p>
<p><img src="assets/assets20180805/output_53_2.png" alt="png"></p>
<p>Now let&rsquo;s look at something that shouldn&rsquo;t really have too much seasonality, the term eclipse. Eclipses happen on a regular basis, of course, and physics predicts them extremely accurately, but human observation of eclipses happens irregularly. Here we can see that the major eclipse event of 2017 is so strongly represented in the data that it ends of defining the very inacurate model that results.</p>
<pre><code class="language-python">prophet_wiki_df('Eclipse')
</code></pre>
<p><img src="assets/assets20180805/output_55_0.png" alt="png"></p>
<p><img src="assets/assets20180805/output_55_1.png" alt="png"></p>
<p><img src="assets/assets20180805/output_55_2.png" alt="png"></p>
<p>We can see the fading of pop culture stars, such as the declining trend with Beyonce. Again, we see that the none of the output here is very trustworthy except perhaps the overall trend. Events such as awards ceremonies, album releases, and gossip events result in spikes which then dominate the seasonality models.</p>
<pre><code class="language-python">prophet_wiki_df('Beyonc√©')
</code></pre>
<p><img src="assets/assets20180805/output_61_0.png" alt="png"></p>
<p><img src="assets/assets20180805/output_61_1.png" alt="png"></p>
<p><img src="assets/assets20180805/output_61_2.png" alt="png"></p>
<p>Returning to our theme above that some wiki topics breathe with the school year, electron is surely one of those topics.</p>
<pre><code class="language-python">prophet_wiki_df('Electron')
</code></pre>
<p><img src="assets/assets20180805/output_63_0.png" alt="png"></p>
<p><img src="assets/assets20180805/output_63_1.png" alt="png"></p>
<p><img src="assets/assets20180805/output_63_2.png" alt="png"></p>
<h2 id="conclusions">Conclusions</h2>
<p>Statistical tools for seasonal decomposition are a great start in trying to predict time series which have some predictability built in. For topics that have a much greater stochastic characteristic, these tools become much more difficult to use properly. Blog entries here will continue to explore these tools and go into greater detail about the math behind them and how to use the tools in more sophisticated ways. Initial impressions from this exploration here:</p>
<ul>
<li>
<p>There are some time series which are nearly perfectly predictable, such as that for the page hits on the topic of Christmas, which is an event that happens once per year and is limited in scope to a small minority of weeks in the entire year.</p>
</li>
<li>
<p>Other trends are fairly predictable, such as electron, because of its association with school work and the predictable seasonality of school. Interestingly, the trends one finds with topics like this show the &ldquo;hit&rdquo; that the holiday break seems to have on education, where the end of year break is preceeded with a sort of winding down and then followed by a winding up, both of which are not particularly rapid.</p>
</li>
<li>
<p>Trends that have an educational component, such as popular US Presidents like Abraham Lincoln, are complicated by holidays such as president&rsquo;s day, elections, and inaugurations.</p>
</li>
<li>
<p>Trends from pop culture, such as Beyonce, can possibly trace the popularity of a celebrity but, are complicated by things such as album releases, awards ceremonies, gossip outbreaks, etc.</p>
</li>
<li>
<p>Sometimes, a massive surge in interest in a topic due to some even can entirely throw off seasonal decomposition, and such events will have to be &lsquo;windowed out&rsquo; and interpolated to get an accurate picture of the routine behavior of the time series.</p>
</li>
<li>
<p>Some topics show the decline in interest in the topic in general, or in some cases, an increasing normalization of a topic such that it gets less page views over time.</p>
</li>
<li>
<p>Some topics are so random that speaking about trends and seasonality is nonsense. However, these models can easily overfit that data and give you a false sense of confidence that will inevitably be proven wrong.</p>
</li>
</ul>

  </main>
  <div id="disqus-container">
  
</div>


          
            <footer role="contentinfo">
  <div
  
  >
    <label for="themer">
      dark theme: <input type="checkbox" id="themer" class="vh">
      
      <span aria-hidden="true"></span>
    </label>
  </div>
  
    Made with <a href="https://gohugo.io/">Hugo</a>. Themed by <a href="https://github.com/zwbetz-gh/cupper-hugo-theme">Cupper</a>.
  
</footer>

          
        </div>
      </div>
    </div>
    

<script src="/js/dom-scripts.js"></script>  

<script src="/js/prism.js"></script>



<script src="/js/search.7aef046a0cc8b0c532f1d20087b920459bc868c936bb48a6ae221eceefca2d07.js"></script>

<link rel="stylesheet" href="/css/search.fe0cd54a21628574bff49d721c827d1bb165ab56b0f22dd55ae78addbe61c309.css"></link>




    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.css" integrity="sha384-dbVIfZGuN1Yq7/1Ocstc1lUEm+AT+/rCkibIcC/OmWo5f0EA48Vf8CytHzGrSwbQ" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.js" integrity="sha384-2BKqo+exmr9su6dir+qCw08N2ZKRucY4PrGQPPWU1A7FtlCGjmEGFqXCv5nyM5Ij" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>

    
  

  </body>
</html>
